import spacy
from spacy import displacy
import json
from POS import Word
from SentenceReadingAgent import POS 


nlp = spacy.load("en_core_web_sm")
doc = nlp("Ada brought a short note to Irene.")

# for token in doc:
#     print(token.text, token.lemma_, token.pos_, token.tag_, token.dep_,
#             token.shape_, token.is_alpha, token.is_stop)
    
# Using readlines()
file1 = open('mostcommon.txt', 'r')
Lines = file1.readlines()

dictionary = {}
  
count = 0
# Strips the newline character
for line in Lines:
    count += 1
    
    doc = nlp(line.strip())
    token = doc[0]
    text = token.text
    line = line.lower()
    line = line.replace("\n","")
    posList = []
    posList.append(token.pos_)
    isStop = token.is_stop

    #Override the original POS
    if line == 'bobbie':
        posList = ["PROPN"]
    elif line == 'irene':
        posList = ["PROPN"]
    elif line == 'jose':
        posList = ["PROPN"]
    elif line == 'meredith':
        posList = ["PROPN"]
    elif line == 'yeeling':
        posList = ["PROPN"]
    elif line == 'yan':
        posList = ["PROPN"]

    elif line == 'cry':
        posList = ["VERB"]   
    elif line == 'noun':
        posList = ["NOUN"]   
    elif line == 'box':
        posList = ["NOUN"]   
    
    elif line == 'note':
        posList = ["NOUN","VERB"]
    elif line == 'fly':
        posList = ["NOUN","VERB"]

    elif line == 'mile':
        posList = ["DIST", "NOUN"]
    elif line == 'inch':
        posList = ["DIST", "NOUN"]
    elif line == 'feet':
        posList = ["DIST", "NOUN"]
    elif line == 'foot':
        posList = ["DIST", "NOUN"]

    elif line == 'was':
        posList = ["VERB"]

    elif line == 'to':
        posList = ["PART","ADP"]

    elif line == 'long':
        posList = ["ADJ","ADV"]

    elif line == 'a':
        posList = ["X"]

    posLine = f"|>{',|>'.join(posList)}"
    dictionary[line] = f"|Word(text='{text}', lemma='{token.lemma_}', posList=[{posLine}], isStop={isStop})|"

print(dictionary)

with open("preprocessing.json", "w") as outfile:
    json.dump(dictionary, outfile, indent=4)


# Using readlines()
file1 = open('preprocessing.json', 'r')
Lines = file1.readlines()
newLines = []
for line in Lines:
    line = line.replace("\"|","")
    line = line.replace("|\"","")
    line = line.replace("|>","POS.")
    newLines.append(line)

with open("PreprocessingDict.py", "w") as outfile:
    outfile.writelines("#NOTE TO SELF: THIS IS A GENERATED CLASS, DO NOT EDIT JEREMIAH\n")
    outfile.writelines("from POS import POS\n")
    outfile.writelines("from POS import Word\n")
    outfile.writelines("\nclass PreprocessingDict:")
    outfile.writelines("\n\twordDict=")
    outfile.writelines(newLines)
    # json.dump(dictionary, outfile, indent=4)
